{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T02:21:03.097773Z",
     "start_time": "2019-05-09T02:20:51.059780Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T06:45:38.056506Z",
     "start_time": "2019-05-09T06:45:34.049431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked\n",
      "0                                     wow love place      1\n",
      "1                                         crust good      0\n",
      "2                                 tasti textur nasti      0\n",
      "3  stop late may bank holiday rick steve recommen...      1\n",
      "4                            select menu great price      1\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Passing result_type=’expand’ will expand list-like results to columns of a Dataframe\n",
    "dataset=pd.read_csv('Restaurant_Reviews.tsv',delimiter='\\t')\n",
    "#processe data\n",
    "def processing(row):\n",
    "    #只留下字母，清除部分用' '代替\n",
    "    review= re.sub('[^a-zA-z]',' ',row['Review'] ).lower().split()\n",
    "    #词根化\n",
    "    ps=PorterStemmer()\n",
    "    #去除虚词\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    return review\n",
    "\n",
    "dataset['Review']=dataset.apply(processing,axis=1)\n",
    "print(dataset.head())\n",
    "print(len(dataset.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T06:45:38.121637Z",
     "start_time": "2019-05-09T06:45:38.110611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked  selectMarker\n",
      "1                                         crust good      0      0.393081\n",
      "2                                 tasti textur nasti      0      0.623970\n",
      "3  stop late may bank holiday rick steve recommen...      1      0.637877\n",
      "5                            get angri want damn pho      0      0.299172\n",
      "6                                honeslti tast fresh      0      0.702198\n",
      "762\n",
      "753\n"
     ]
    }
   ],
   "source": [
    "#split data into training and testing\n",
    "np.random.seed(2019)\n",
    "dataset['selectMarker']=np.random.uniform(0,1,len(dataset.index))\n",
    "# uniformly distributed,0.75 train\n",
    "trainSet=dataset[dataset['selectMarker']<0.75]\n",
    "testSet=dataset[dataset['selectMarker']>=0.25]\n",
    "print(trainSet.head())\n",
    "print(len(trainSet.index))\n",
    "print(len(testSet.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T06:58:21.579127Z",
     "start_time": "2019-05-09T06:58:21.565589Z"
    }
   },
   "outputs": [],
   "source": [
    "class classifier:\n",
    "    def __init__(self,trainSet):\n",
    "        self.pro=len(trainSet[trainSet['Liked']==1])\n",
    "        self.anti=len(trainSet[trainSet['Liked']==0])\n",
    "        self.prori=[self.anti/(self.pro+self.anti),self.pro/(self.pro+self.anti)]\n",
    "        self.proWord={}\n",
    "        self.antiWord={}\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range (len(trainSet['Review'].index)):\n",
    "            if trainSet['Liked'].iloc[i]==1:\n",
    "                for word in trainSet['Review'].iloc[i].split(' '):\n",
    "                    if word not in self.proWord:\n",
    "                        self.proWord[word]=1/self.pro\n",
    "                    else:\n",
    "                        self.proWord[word]+=1/self.pro\n",
    "            elif trainSet['Liked'].iloc[i]==0:\n",
    "                 for word in trainSet['Review'].iloc[i].split(' '):\n",
    "                    if word not in self.antiWord:\n",
    "                        self.antiWord[word]=1/self.anti\n",
    "                    else:\n",
    "                        self.antiWord[word]+=1/self.anti\n",
    "    def predict(self,testRow):\n",
    "        result=[1,1]\n",
    "        for word in testRow.split(' '):\n",
    "            if word in self.proWord:\n",
    "                result[1]*=self.proWord[word]\n",
    "            else:\n",
    "                result[1]*=1/(self.pro+len(self.proWord)+len(self.antiWord)) #Laplace smoothing\n",
    "        for word in testRow.split(' '):\n",
    "            if word in self.antiWord:\n",
    "                result[0]*=self.antiWord[word]\n",
    "            else:\n",
    "                result[0]*=1/(self.anti+len(self.proWord)+len(self.antiWord))\n",
    "        result[0]*=self.prori[0]\n",
    "        result[1]*=self.prori[1]\n",
    "        return np.argmax(result)\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T06:58:22.261668Z",
     "start_time": "2019-05-09T06:58:22.192492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9110225763612217\n"
     ]
    }
   ],
   "source": [
    "tmp= classifier(trainSet)\n",
    "tmp.train()\n",
    "cnt=0\n",
    "for i in range (len(testSet['Liked'].index)):\n",
    "    if tmp.predict(testSet['Review'].iloc[i])==testSet['Liked'].iloc[i]:\n",
    "        cnt+=1\n",
    "#     else:\n",
    "#         print(testSet['Review'].iloc[i],testSet['Liked'].iloc[i],tmp.predict(testSet['Review'].iloc[i]))\n",
    "print(cnt/len(testSet.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T06:19:04.012544Z",
     "start_time": "2019-05-09T06:19:03.989500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
